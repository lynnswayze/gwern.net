---
title: About This Website
description: Meta page describing Gwern.net site ideals of stable long-term essays which improve over time; idea sources and writing methodology; metadata definitions; site statistics; copyright license.
thumbnail: /doc/design/2022-04-13-gwern-gwernnet-index-desktop-small.png
thumbnail-text: "Screenshot of the website Gwern.net’s homepage mid-2022 (small desktop view), showing sidebar, logo, introduction, and first 2 sections of links to essays. It is a minimalist monochrome design emphasizing powerful link popup capabilities."
thumbnail-css: "outline invert-not"
created: 2010-10-01
modified: 2024-08-30
status: finished
confidence: highly likely
importance: 3
css-extension: dropcaps-de-zs
...

<div class="abstract">
> This page is about Gwern.net content; for the details of its implementation & design like the popup paradigm, see [Design](/design "'Design Of This Website', Branwen 2010"){.backlink-not}; and for information about me, see [Links](/me "'About Gwern', Branwen 2009"){.backlink-not}.
</div>

# The Content

<div class="epigraph">
> Of all the books I have delivered to the presses, none, I think, is as personal as the straggling collection mustered for this hodgepodge, precisely because it abounds in reflections and interpolations. Few things have happened to me, and I have read a great many. Or rather, few things have happened to me more worth remembering than Schopenhauer's thought or the music of England's words.
>
> A man sets himself the task of portraying the world. Through the years he peoples a space with images of provinces, kingdoms, mountains, bays, ships, islands, fishes, rooms, instruments, stars, horses, and people. Shortly before his death, he discovers that that patient labyrinth of lines traces the image of his face.
>
> [Jorge Luis Borges](!W), _[Dreamtigers](!W)_ [Epilogue](https://thefloatinglibrary.com/2008/12/09/dreamtigers-epiloge-j-l-borges/)
</div>

The content here varies from [statistics](/google-shutdown "'Predicting Google closures', Branwen 2013") to [psychology](/dnb-faq "'Dual n-Back FAQ', Branwen 2009") to [self-experiments](/zeo/zeo "'Zeo sleep self-experiments', Branwen 2010")/[Quantified Self](/weather "'Weather and My Productivity', Branwen 2013") to [philosophy](/culture-is-not-about-esthetics "'Culture Is Not About Esthetics', Branwen 2009") to [poetry](/fiction/brave-poem "'Brave Poem', Branwen 2010") to [programming](/haskell/wikipedia-rss-archive-bot "'Writing a Wikipedia RSS Link Archive Bot', Branwen 2009") to [anime](/otaku "'Neon Genesis Evangelion source anthology', Branwen 2009") to investigations of [online drug markets](/silk-road "'Silk Road 1: Theory & Practice', Branwen 2011") or [leaked movie scripts](/death-note-script "'Who Wrote The ‘Death Note’ Script?', Branwen 2009") (or two topics at once: [anime & statistics](/hafu "'Hafu Gender Ratios in Anime', Branwen 2011") or [anime & criticism](/death-note-ending "'Death Note’s Ending', Branwen 2008") or heck [anime & statistics & criticism](/death-note-anonymity "'Death Note: L, Anonymity & Eluding Entropy', Branwen 2011")!).

I believe that someone who has been well-educated will think of something worth writing at least once a week; to a surprising extent, this has been true.
(I added ~130 documents to this repository over the first 3 years.)

## Target Audience

<span id="tayget-audience"></span>

<div class="epigraph">
> Special knowledge can be a terrible disadvantage if it leads you too far along a path you cannot explain anymore.
>
> [Brian Herbert](!W) (_[Dune: House Harkonnen](!W)_)
</div>

I don't write simply to find things out, although curiosity is my primary motivator, as I find I want to read something which hasn't been written---"...I realised that I wanted to read about them what I myself knew. More than this---what only I knew.
Deprived of this possibility, I decided to write about them. Hence this book."^[[Gennadi Sosonko](!W), pg 19 of [_Russian Silhouettes_](https://www.amazon.com/Russian-Silhouettes-Genna-Sosonko/dp/9056912933/), on why he wrote his book of biographical sketches of great Soviet chess players. (As Richardson asks (_Vectors 1.0_, 2001): "25. Why would we write if we'd already heard what we wanted to hear?")]
There are many benefits to keeping notes as they allow one to accumulate confirming and especially contradictory evidence[^Darwin], and even drafts can be useful so you [Don’t Repeat Yourself](!W) or simply decently respect the opinions of mankind.

[^Darwin]: One danger of such an approach is that you will simply engage in [confirmation bias](!W), and build up an impressive-looking wall of citations that is completely wrong but effective in brainwashing yourself. The only solution is to be diligent to include criticism---so even if you do not escape brainwashing, at least your readers have a chance. _[The Autobiography of Charles Darwin](!W)_, Darwin 1902:

    > I had, also, during many years followed a golden rule, namely, that whenever a published fact, a new observation or thought came across me, which was opposed to my general results, to make a memorandum of it without fail and at once; for I had found by experience that such facts and thoughts were far more apt to escape from the memory than favourable ones. Owing to this habit, very few objections were raised against my views which I had not at least noticed and attempted to answer.

The goal of these pages is not to be a model of concision, maximizing entertainment value per word, or to preach to a choir by elegantly repeating a conclusion.
Rather, I am attempting to explain things to my future self, who is intelligent and interested, but has forgotten.
What I am doing is explaining why I decided what I did to myself and noting down everything I found interesting about it for future reference.
I hope my other readers, whomever they may be, might find the topic as interesting as I found it, and the essay useful or at least entertaining--but the intended audience is my future self.

## Development

<div class="epigraph">
> I hate the water that thinks that it boiled itself on its own. I hate the seasons that think they cycle naturally. I hate the sun that thinks it rose on its own.
>
> Sodachi Oikura, _[Owarimonogatari](!W)_ (Sodachi Riddle, Part One)
</div>

It is everything I felt worth writing that didn't fit somewhere like Wikipedia or was already written.
I never expected to write so much; but I discovered that once I had a hammer, nails were everywhere, and that [supply creates its own demand](!W "Say’s Law")^["It is only the attempt to write down your ideas that enables them to develop." --Wittgenstein (pg 109, [_Recollections of Wittgenstein_](https://www.amazon.com/Recollections-Wittgenstein-Hermine/dp/0192876287/)); "I thought a little [while in the isolation tank], and then I stopped thinking altogether...incredible how idleness of body leads to idleness of mind. After 2 days, I'd turned into an idiot. That's the reason why, during a flight, astronauts are always kept busy." --Oriana Fallaci, [quoted](https://www.johndcook.com/blog/2010/12/11/after-two-days-id-turned-into-an-idiot/) in [_Rocket Men: The Epic Story of the First Men on the Moon_](https://www.amazon.com/Rocket-Men-Epic-Story-First/dp/B002VPE85K/) by Craig Nelson. See also [Beatriz Flamini](https://www.newyorker.com/magazine/2024/01/29/the-woman-who-spent-five-hundred-days-in-a-cave).].

## Long Site

<div class="epigraph">
> The Internet is self destructing paper. A place where anything written is soon destroyed by rapacious competition and the only preservation is to forever copy writing from sheet to sheet faster than they can burn. If it's worth writing, it's worth keeping. If it can be kept, it might be worth writing...If you store your writing on a third party site like [Blogger](!W), [Livejournal](!W) or even on your own site, but in the complex format used by blog/wiki software du jour you will *lose it forever* as soon as hypersonic wings of Internet labor flows direct people's energies elsewhere. For most information published on the Internet, perhaps that is *not a moment too soon*, but how can the muse of originality soar when immolating transience brushes every feather?
>
> [Julian Assange](!W) (["Self destructing paper"](/doc/technology/2007-assange-iq.org.html#Selfdestructingpaper "https://web.archive.org/web/20071020051936/http://iq.org/"), 2006-12-05)
</div>

One of my personal interests is applying the idea of the [Long Now](!W). What and how do you write a personal site with the long-term in mind? We live most of our lives in the future, and the actuarial tables give me until the 2070--2080s, excluding any benefits from [caloric restriction](!W)/[intermittent fasting](!W) or projects like [SENS](!W "Strategies for Engineered Negligible Senescence"). It is a common-place in science fiction^[Such as [Larry Niven's](!W "Larry Niven") [Known Space](!W) universe; consider the introduction to the chronologically last story in that setting, "Safe at Any Speed" (_Tales of Known Space_).] that longevity would cause widespread risk aversion. But on the other hand, it could do the opposite: the longer you live, the more long-shots you can afford to invest in. Someone with a timespan of 70 years has reason to protect against black swans---but also time to look for them.[^Fromm] It's worth noting that old people make many short-term choices, as reflected in increased suicide rates and reduced investment in education or new hobbies, and this is not due solely to the ravages of age but the proximity of death---the HIV-infected (but otherwise in perfect health) act similarly short-term.[^Posner]

[^Fromm]: [Erich Fromm](!W):

    > "If the individual lived five hundred or one thousand years, this clash (between his interests and those of society) might not exist or at least might be considerably reduced. He then might live and harvest with joy what he sowed in sorrow; the suffering of one historical period which will bear fruit in the next one could bear fruit for him too."
[^Posner]: From [Richard Posner's](!W "Richard Posner") [_Aging and Old Age_](https://www.amazon.com/Aging-Old-Age-Richard-Posner/dp/0226675688/):

    > One way to distinguish empirically between aging effects and proximity-to-death effects would be to compare, with respect to choice of occupation, investment, education, leisure activities, and other activities, elderly people on the one hand with young or middle-aged people who have truncated life expectancies but are in apparent good health, on the other. For example, a person newly infected with the AIDS virus (HIV) has roughly the same life expectancy as a 65-year-old and is unlikely to have, as yet, [major] symptoms. The conventional human-capital model implies that, after correction for differences in income and for other differences between such persons and elderly persons who have the same life expectancy (a big difference is that the former will not have pension entitlements to fall back upon), the behavior of the two groups will be similar. It does appear to be similar, so far as investing in human capital is concerned; the truncation of the payback period causes disinvestment. And there is a high suicide rate among HIV-infected persons (even before they have reached the point in the progression of the disease at which they are classified as persons with AIDS), just as there is, as we shall see in chapter 6, among elderly persons.

What sort of writing could you create if you worked on it (be it ever so rarely) for the next 60 years? What could you do if you started *now*?[^JFK]

[^JFK]: [John F. Kennedy](https://millercenter.org/the-presidency/presidential-speeches/march-23-1962-address-university-california-berkeley#dp-expandable-text "Address at the University of California, Berkeley (March 23, 1962)"), 1962:

    > I am reminded of the story of the great French Marshal Lyautey, who once asked his gardener to plant a tree. The gardener objected that the tree was slow-growing and would not reach maturity for a hundred years. The Marshal replied, "In that case, there is no time to lose, plant it this afternoon."

Keeping the site running that long is a challenge, and leads to the recommendations for [Resilient Haskell Software](/resilient-software): 100% [FLOSS](!W) software[^zeroth], [open standards](!W "Open format") for data, [textual](http://catb.org/~esr/writings/taoup/html/ch05s01.html) human-readability, avoiding external dependencies[^bitly-1][^bitly-2], and staticness[^staticness].

[^zeroth]: [Mark Pilgrim](!W), ["Freedom 0"](/doc/technology/2004-pilgrim-freedom0.html "https://web.archive.org/web/20110726001925/http://diveintomark.org/archives/2004/05/14/freedom-0"):

    > In the long run, the utility of all non-Free software approaches zero. All non-Free software is a dead end.
[^bitly-1]: These dependencies can be subtle. Computer archivist Jason Scott [writes](http://ascii.textfiles.com/archives/3029) of [URL shortening](!W "URL shortening#Shortcomings") services that:

    > URL shorteners may be one of the worst ideas, one of the most backward ideas, to come out of the last five years. In very recent times, per-site shorteners, where a website registers a smaller version of its hostname and provides a single small link for a more complicated piece of content within it... those are fine. But these general-purpose URL shorteners, with their shady or fragile setups and utter dependence upon them, well. If we lose [TinyURL](!W) or [bit.ly](!W), millions of weblogs, essays, and non-archived tweets lose their meaning. Instantly. To someone in the future, it'll be like everyone from a certain era of history, say ten years of the 18th century, started speaking in a one-time pad of cryptographic pass phrases. We're doing our best to stop it. Some of the shorteners have been helpful, others have been hostile. A number have died. We're going to release torrents on a regular basis of these spreadsheets, these code breaking spreadsheets, and we hope others do too.
[^bitly-2]: [Joshua Schachter](!W) [remarks](http://joshua.schachter.org/2009/04/on-url-shorteners) (and the comments provide even more examples) further on URL shorteners:

    > But the biggest burden falls on the clicker, the person who follows the links. The extra layer of indirection slows down browsing with additional DNS lookups and server hits. A new and [potentially unreliable middleman](https://slashdot.org/story/07/11/18/1319201/do-tiny-url-services-weaken-net-architecture) now sits between the link and its destination. And the long-term archivability of the hyperlink now depends on the health of a third party. The shortener may decide a link is a Terms Of Service violation and delete it. If the shortener [accidentally erases a database](https://www.wired.com/2009/01/magnolia-suffer/ "‘Ma.gnolia Suffers Major Data Loss, Site Taken Offline’, Calore 2009"), forgets to renew its domain, or just [disappears](https://6uold.blogspot.com/2008/06/long-list-of-url-shorteners.html), the link will break. If a top-level domain [changes its policy on commercial use](https://workbench.cadenhead.org/news/3503/bitly-builds-business-libya-domain), the link will break. If the shortener gets hacked, every link becomes a potential phishing attack.
[^staticness]: A static text-source site has many advantages for Long Content that I consider use almost a no-brainer.

    - By nature, they compile most content down to flat standalone textual files, which allow recovery of content even if the original site software has bit-rotted or the source files have been lost or the compiled versions cannot be directly used in new site software: one can parse them with XML tools or with quick hacks or by eye.
    - Site compilers generally require dependencies to be declared up front, and the approach makes explicitness and content easy, but dynamic interdependent components difficult, all of which discourages creeping complexity and hidden state.
    - A static site can be archived into a tarball of files which will be readable as long as web browsers exist (or afterwards if the HTML is reasonably clean), but it could be difficult to archive a CMS like WordPress or Blogspot (the latter doesn't even provide the content in HTML---it only provides a rat's-nest of inscrutable JavaScript files which then download the content from *somewhere* and display it *somehow*; indeed, I'm not sure how I would automate archiving of such a site if I had to; I would need some sort of headless browser to run the JS and serialize the final resulting DOM, possibly with some scripting of mouse/keyboard actions).
    - The content is often not available locally, or is stored in opaque binary formats rather than text (if one is lucky, it will at least be a database), both of which make it difficult to port content to other website software; you won't have the necessary pieces, or they will be in wildly incompatible formats.
    - Static sites are usually written in a reasonably standardized markup language such as Markdown or <span class="logotype-latex">L<span class="logotype-latex-a">a</span>T<span class="logotype-latex-e">e</span>X</span>, in distinction to blogs which force one through WYSIWYG editors or invent their own markup conventions, which is yet another barrier: parsing a possibly ill-defined language.
    - The lowered sysadmin efforts (who wants to be constantly cleaning up spam or hacks on their WordPress blog?) are a final advantage: lower running costs make it more likely that a site will stay up rather than cease to be worth the hassle.

    Static sites are not appropriate for many kinds of websites, but they are appropriate for websites which are content-oriented, do not need interactivity, expect to migrate website software several times over coming decades, want to enable archiving by oneself or third parties ("lots of copies keeps stuff safe"), and to gracefully degrade after loss or bitrot.

Preserving the content is another challenge. Keeping the content in a [DVCS](!W "Distributed version control") like [git](!W "Git (software)") protects against file corruption and makes it easier to mirror the content; regular backups^[Such as burning the occasional copy onto read-only media like DVDs.] help. I have taken additional measures: [WebCitation](!W) has archived most pages and almost all external links; the [Internet Archive](!W) is also archiving pages & external links^[One can't be sure; the IA is fed by [Alexa](!W "Alexa Internet"), and Alexa doesn't guarantee pages will be [spidered](!W "Web crawler") & preserved if one goes through their request form.]. (For details, read [Archiving URLs](/archiving "'Archiving URLs', Branwen 2011").)

One could continue in this vein, devising ever more powerful & robust storage methods (perhaps combine the DVCS with [forward error correction](!W) through [PAR2](!W "Parchive"), a la [bup](https://lwn.net/Articles/380983/)), but what is one to fill the storage with?

## Long Content

<div class="epigraph">
> What has been done, thought, written, or spoken is not culture; culture is only that fraction which is *remembered*.
>
> Gary Taylor ([_The Clock of the Long Now_](https://www.amazon.com/Clock-Long-Now-Responsibility-Computer/dp/0465007805/); emphasis added)^[I am diligent in backing up my files, in periodically copying my content from the [cloud](!W "Cloud computing"), and in preserving viewed Internet content; why do I do all this? Because I want to believe that my memories are precious, that the things I saw and said are valuable; "I want to meet them again, because I believe my feelings at that time were real." My past is not trash to me, used up & discarded.]
</div>

'Blog posts' might be the answer. But I have read blogs for many years and most blog posts are the triumph of the hare over the tortoise. They are meant to be read by a few people on a weekday in 2004 and never again, and are [quickly](https://www.nytimes.com/2009/06/07/fashion/07blogs.html "Blogs Falling in an Empty Forest") [abandoned](/doc/technology/2009-arnold-bloggingstatisticsanddemographics.html "'blog statistics and demographics', Bruce Arnold 2009")---and perhaps as Assange says, not a moment too soon. (But isn't that sad? Isn't it a terrible [ROI](!W "Rate of return") for one's time?) On the other hand, the best blogs always seem to be building something: they are rough drafts---works in progress[^books]. So I did not wish to write a blog. Then what? More than just "evergreen content", what would constitute *Long* Content as opposed to the existing culture of Short Content? How does one live in a Long Now sort of way?[^Kelly]

[^books]: Examples of such blogs:

     #. [Eliezer Yudkowsky's](!W "Eliezer Yudkowsky") contributions to [LessWrong](https://www.lesswrong.com/) were the rough draft of a philosophy book (or two)
     #. [John Robb's](https://en.wikipedia.org/wiki/John_Robb_%28military_theorist%29) [Global Guerrillas](https://globalguerrillas.typepad.com/) lead to his [_Brave New War: The Next Stage of Terrorism and the End of Globalization_](https://www.amazon.com/exec/obidos/ASIN/0471780790/)
     #. [Kevin Kelly's](!W "Kevin Kelly (editor)") [Technium](https://kk.org/thetechnium/) was turned into [_What Technology Wants_](https://www.amazon.com/What-Technology-Wants-Kevin-Kelly/dp/0670022152/).

     An example of how *not* to do it would be [Robin Hanson's](!W "Robin Hanson") [Overcoming Bias](https://www.overcomingbias.com/) blog; it is stuffed with fascinating citations & sketches of ideas, but they never go anywhere with the exception of his mind emulation economy posts which were eventually published in 2016 as [_The Age of Em_](https://ageofem.com/). Just his posts on [medicine](https://web.archive.org/web/20230101001643/https://www.overcomingbias.com/tag/medicine) would make a fascinating essay or just list---but he has never made one. (["Showing That You Care: The Evolution of Health Altruism"](/doc/economics/2008-hanson.pdf "'Showing that you care: The evolution of health altruism', Hanson 2008") would be a natural home for many of his posts' contents, but will never be updated.) Kevin Simler stepped up to help write [_The Elephant in the Brain: Hidden Motives in Everyday Life_](https://www.elephantinthebrain.com/), and that seems to be the closest we'll ever get.
[^Kelly]: ["Kevin Kelly Answers Your Questions"](https://interviews.slashdot.org/story/11/09/06/1458254/Kevin-Kelly-Answers-Your-Questions), 2011-09-06:

    > [Question:] "One purpose of the [Long Now Clock](!W) is to encourage long-term thinking. Aside from the Clock, though, what do you think people can do in their everyday lives to adopt or promote long-term thinking?"
    >
    > [KK](!W "Kevin Kelly (editor)"): "The 10,000-year Clock we are building [in the hills of west Texas](http://10000yearclock.net/) is meant to remind us to think long-term, but learning how to do that as in individual is difficult. Part of the difficulty is that as individuals we constrained to short lives, and are inherently not long-term. So part of the skill in thinking long-term is to place our values and energies in ways that transcend the individual---either in generational projects, or in social enterprises."
    >
    > "As a start I recommend engaging in a project that will not be complete in your lifetime. Another way is to require that your current projects exhibit some payoff that is not immediate; perhaps some small portion of it pays off in the future. A third way is to create things that get better, or run up in time, rather than one that decays and runs down in time. For instance a seedling grows into a tree, which has seedlings of its own. A program like [Heifer Project](!W) which gives breeding pairs of animals to poor farmers, who in turn must give one breeding pair away themselves, is an exotropic scheme, growing up over time."

> It's shocking to find how many people do not believe they can learn, and how many more believe learning to be difficult. Muad'Dib knew that every experience carries its lesson.^['Princess Irulan', [Frank Herbert](!W), [_Dune_](!W "Dune (novel)")]

My answer is that one uses such a framework to work on projects that are too big to work on normally or too tedious. (Conscientiousness is often lacking online or in volunteer communities[^no-good-volunteers] and many useful things go undone.) Knowing your site *will* survive for decades to come gives you the mental wherewithal to tackle long-term tasks like gathering information for years, and such persistence can be useful^[An old sentiment; consider "A drop hollows out the stone" (Ovid, _Epistles_) or Thomas Carlyle's "The weakest living creature, by concentrating his powers on a single object, can accomplish something. The strongest, by dispensing his over many, may fail to accomplish anything. The drop, by continually falling, bores its passage through the hardest rock. The hasty torrent rushes over it with hideous uproar, and leaves no trace behind." (_The life of Friedrich Schiller_, 1825)]---if one holds onto every glimmer of genius for years, then even the dullest person may look a bit like a genius himself[^Feynman]. (Even experienced professionals can only write at their peak for a few hours a day---usually [first thing in the morning](/morning-writing "'What Is The Morning Writing Effect?', Branwen 2011"), it seems.) Half the challenge of fighting procrastination is the [pain of starting](https://www.lesswrong.com/posts/9o3QBg2xJXcRCxGjS/working-hurts-less-than-procrastinating-we-fear-the-twinge)---I find when I actually get [into the swing](https://www.lesswrong.com/posts/9o3QBg2xJXcRCxGjS/working-hurts-less-than-procrastinating-we-fear-the-twinge) of working on even dull tasks, it's not so bad. So this suggests a solution: never start. Merely have perpetual drafts, which one tweaks from time to time. And the rest takes care of itself. I have a few examples of this:

[^no-good-volunteers]: [GiveWell](!W) reports in ["A good volunteer is hard to find"](https://blog.givewell.org/2011/07/13/a-good-volunteer-is-hard-to-find/) that of volunteers motivated enough to email them asking to help, something like <20% will complete the GiveWell test assignment and render meaningful help. It is difficult to make any good use of volunteers (an observation quietly echoed by others in the [nonprofit](https://seliger.com/2014/04/20/volunteers-nonprofits-really-want-their-money-not-their-bodies/) [world](https://www.nytimes.com/2014/04/20/opinion/sunday/being-good-isnt-the-only-way-to-go.html)). Such persons would have been well-advised to have simply donated some money. I have long noted that many of the most popular pages on Gwern.net could have been written by anyone and drew on no unique talents of mine; I have on several occasions received offers to help with the DNB FAQ---none of which have resulted in *actual* help.
[^Feynman]: ["Ten Lessons I wish I had been Taught"](/doc/math/1996-04-20-rota-tenlessonsiwishihadbeentaught.html#feynmann), [Gian-Carlo Rota](!W):

    > Richard Feynman was fond of giving the following advice on how to be a genius. You have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say: '*How did he do it? He must be a genius*!'

#. [DNB FAQ](/dnb-faq "'Dual n-Back FAQ', Branwen 2009"){#gwern-dnb-faq-2}:

     When I read in _Wired_ in 2008 that the obscure working memory exercise called dual _n_-back (DNB) had been found to increase IQ substantially, I was shocked. IQ is one of the most stubborn properties of one's mind, one of the most fragile[^fragile], the hardest to affect positively, but also one of the most valuable traits one could have[^conscientiousness]; if the technique panned out, it would be *huge*. Unfortunately, DNB requires a major time investment (as in, half an hour daily); which would be a bargain---if it delivers. So, to do DNB or not?

     Questions of great import like this are worth studying carefully. The wheels of academia grind exceeding slow, and only a fool expects unanimous answers from fields like psychology. Any attempt to answer the question 'is DNB worthwhile?' will require years and cover a breadth of material. This FAQ on DNB is my attempt to cover that breadth over those years.
#. [_Neon Genesis Evangelion_ notes](/otaku "'Neon Genesis Evangelion source anthology', Branwen 2009"){#otaku-2}:

    I have been discussing [NGE](!W "Neon Genesis Evangelion") since 2004. The task of interpreting Eva is very difficult; the source works themselves are a major time-sink^[25 episodes, 6 movies, >11 manga volumes---just to stick to the core works.], and there are thousands of primary, secondary, and tertiary works to consider---personal essays, interviews, reviews, etc. The net effect is that many Eva fans 'know' certain things about Eva, such as _[End of Evangelion](!W)_ not being a grand 'screw you' statement by Hideaki Anno or that the TV series was censored, but they no longer have *proof*. Because each fan remembers a different subset, they have irreconcilable interpretations. (Half the value of the page for me is having a place to store things I've said in countless fora which I can eventually turn into something more systematic.)

    To compile claims from all those works, to dig up forgotten references, to scroll through microfilms, buy issues of defunct magazines---all this is enough work to shatter [the heart](!W "Karoshi") of the stoutest salaryman. Which is why I began years ago and expect not to finish for years to come. (Finishing by 2020 seems like a good [prediction](https://predictionbook.com/predictions/1951).)
#. [_Cloud Nine_](/fiction/cloud-nine):
    Years ago I was reading the papers of the economist [Robin Hanson](!W). I recommend his work highly; even if they are wrong, they are imaginative and some of the finest speculative fiction I have read. (Except they were non-fiction.) One night I had a dream in which I saw in a flash a medieval city run in part on Hansonian grounds; a [steampunk](!W) version of his [futarchy](!W). A city must have another city as a rival, and soon I had remembered the strange '90s idea of [assassination markets](!W), which was easily tweaked to work in a medieval setting. Finally, between them, was one of my favorite proposals, Buckminster Fuller's [cloud nine](!W "Cloud Nine (tensegrity sphere)") megastructure.

    I wrote several drafts but always lost them. Sad[^Tadamine] and discouraged, I abandoned it for years. This fear leads straight into the next example.
#. A Book reading list:

    Once, I didn't have to keep reading lists. I simply went to the school library shelf where I left off and grabbed the next book. But then I began reading harder books, and they would cite other books, and sometimes would even have horrifying lists of hundreds of other books I ought to read ('bibliographies'). I tried remembering the most important ones but quickly forgot. So I began keeping a book list on paper. I thought I would throw it away in a few months when I read them all, but somehow it kept growing and growing. I didn't trust computers to store it before^[As with _Cloud Nine_; I accidentally erased everything on a routine basis while messing around with Windows.], but now I do, and it lives on in digital form (currently on [Goodreads](/me#websites)---because they have export functionality). With it, I can track how my interests evolved over time^[For example, I notice I am no longer deeply interested in the occult. Hopefully this is because I have grown mentally and recognize it as rubbish; I would be embarrassed if when I died it turned out my youthful self had a better grasp on the real world.], and what I was reading at the time. I sometimes wonder if I will read them all even by 2070.

[^conscientiousness]: For details on the many valuable correlates of the Conscientiousness personality factor, see [Conscientiousness and online education](/conscientiousness#conscientiousness).
[^fragile]: IQ is sometimes used as a proxy for health, like height, because it sometimes seems like any health problem will damage IQ. Didn't get much protein as a kid? Congratulations, your nerves will lack [myelination](!W) and you will literally think slower. Missing some [iodine](/iodine "'Iodine and Adult IQ meta-analysis', Branwen 2012")? Say good bye to <10 points! If you're anemic or iron-deficient, that might increase to <15 points. Have tapeworms? There go some more points, and maybe centimeters off your adult height, thanks to the worms stealing nutrients from you. Have a rough birth and suffer a spot of hypoxia before you began breathing on your own? Tough luck, old bean. It is very easy to *lower* IQ; you can do it with a baseball bat. It's the other way around that's nearly impossible.
[^Tadamine]: [Mibu no Tadamine](!W), [_KKS_ XII: 609](https://www.wakapoetry.net/kks-xii-609/):

        More than my life
        What I most regret
        Is
        A dream unfinished
        And awakening.

What is next? So far the pages will persist through time, and they will gradually improve over time. But a truly Long Now approach would be to make them be improved *by* time---make them more valuable the more time passes. ([Stewart Brand](!W) remarks in _[The Clock of the Long Now](!W)_ that a group of monks carved thousands of scriptures into stone, hoping to preserve them for posterity---but posterity would value far more a carefully preserved collection of monk feces, which would tell us countless valuable things about important phenomenon like global warming.)

One idea I am exploring is adding long-term predictions like the ones I make on [PredictionBook.com](https://predictionbook.com/users/gwern). Many[^fiction] pages explicitly or implicitly make predictions about the future. As time passes, predictions would be validated or falsified, providing feedback on the ideas.^[Thinking of predictions is good mental discipline; we should always be able to [cash out](https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences) our beliefs in terms of the real world, or know why we cannot. Unfortunately, humans being humans, we need to actually track our predictions---[*all* of them](!W "Confirmation bias")---lest our predicting degenerate into [entertainment](https://www.lesswrong.com/posts/mZJs7FxxmhMvFxuse/futuristic-predictions-as-consumable-goods) like political punditry.]

[^fiction]: Some pages don't have any connection to predictions. It's possible to make predictions for some border cases like the terrorism essays (death tolls, achievements of particular groups' policy goals), but what about the short stories or poems? My imagination fails there.

For example, the Evangelion essay's paradigm implies many things about the future movies in _[Rebuild of Evangelion](!W)_^[Dozens of theories have been put forth. I have been collecting & making predictions; and am up to 219. It will be interesting to see how the movies turn out.]; [The Melancholy of Kyon](/kyon) is an extended prediction^[I have 2 predictions registered about the thesis on PB.com: [1 reviewer will accept my theory by 2016](https://predictionbook.com/predictions/1833) and [the light novels will finish by 2015](https://predictionbook.com/predictions/1832).] of future plot developments in _[The Melancholy of Haruhi Suzumiya](!W)_ series; [Haskell Summer of Code](/haskell/summer-of-code "'Summers of Code, 2006–2013', Branwen 2009") has suggestions about what makes good projects, which could be turned into predictions by applying them to predict success or failure when the next Summer of Code choices are announced. And so on.

I don't think "Long Content" is simply for working on things which are equivalent to a "[monograph](!W)" (a work which attempts to be an exhaustive exposition of all that is known---and what has been recently discovered---on a single topic), although monographs clearly would benefit from such an approach. If I write a short essay cynically remarking on, say, Al Gore and predicting he'd sell out and registered some predictions and came back 20 years later to see how it worked out, I would consider this "Long Content" (it gets more interesting with time, as the predictions reach maturation); but one couldn't consider this a "monograph" in any ordinary sense of the word.

One of the ironies of this approach is that as a [transhumanist](!W), I assign non-trivial probability to the world undergoing massive change during the 21<sup>st</sup> century due to any of a number of technologies such as artificial intelligence (such as [mind uploading](!W)^[See Robin Hanson, ["If Uploads Come First"](https://mason.gmu.edu/~rhanson/uploads.html)]) or [nanotechnology](!W "Molecular assembler"); yet here I am, planning as if I and the world were immortal.

I personally believe that one should "think Less Wrong and act Long Now", if you follow me. I diligently do my daily [spaced-repetition review](/spaced-repetition "'Spaced Repetition for Efficient Learning', Branwen 2009") and n-backing; I carefully design my website and writings to last decades, actively think about how to write material that improves with time, and work on writings that will not be finished for years (if ever). It's a bit schizophrenic since both are totalized worldviews with drastically conflicting recommendations about where to invest my time. It's a case of high [discount rates](!W "Time preference") versus low discount rates; and one could fairly accuse me of committing the [sunk cost fallacy](!W), but then, I'm not sure that [sunk cost fallacy is a fallacy](/sunk-cost "'Are Sunk Costs Fallacies?', Branwen 2012") (certainly, I have more to show for my wasted time than most people).

The Long Now views its proposals like the Clock and the Long Library and [seedbanks](!W) as insurance---in case the future turns out to be surprisingly *unsurprising*. I view these writings similarly. If [Ray Kurzweil's](!W "Ray Kurzweil") most ambitious predictions turn out right and the [Singularity](!W "Technological singularity") happens by 2050 or so, then much of my writings will be moot, but I will have all the benefits of said Singularity; if the Singularity never happens or ultimately pays off in a very disappointing way, then my writings will be valuable to me. By working on them, I hedge my bets.

## Finding my ideas

To the extent I personally have any method for 'getting started' on writing something, it's to pay attention to anytime you find yourself thinking, "how irritating that there's no good webpage/Wikipedia article on _X_" or "I wonder if _Y_" or "has anyone done _Z_" or "huh, I just realized that _A_!" or "this is the third time I've had to explain this, jeez."

The DNB FAQ started because I was irritated people were repeating themselves on the dual _n_-back mailing list; the [modafinil](/modafinil) article started because it was a pain to figure out where one *could* order modafinil; the trio of _Death Note_ articles ([Anonymity](/death-note-anonymity "'Death Note: L, Anonymity & Eluding Entropy', Branwen 2011"){#dna-2}, [Ending](/death-note-ending "'Death Note’s Ending', Branwen 2008"){#dne-2}, [Script](/death-note-script "'Who Wrote The ‘Death Note’ Script?', Branwen 2009"){#dns-2}) all started because I had an amusing thought about information theory; the [Silk Road 1](/silk-road "'Silk Road 1: Theory & Practice', Branwen 2011"){#SR-2} page was commissioned after I groused about how deeply sensationalist & shallow & ill-informed all the mainstream media articles on the Silk Road drug marketplace were (similarly for [Bitcoin is Worse is Better](/bitcoin-is-worse-is-better)); my [Google survival analysis](/google-shutdown "'Predicting Google closures', Branwen 2013"){#google-shutdowns-2} was based on thinking it was a pity that Arthur's _Guardian_ analysis was trivially & fatally flawed; and so on and so forth.

None of these seems special to me.
Anyone could've compiled the DNB FAQ; anyone could've kept a list of online pharmacies where one could buy modafinil; someone tried something similar to my Google shutdown analysis before me (and the fancier statistics were all standard tools).
If I have done anything meritorious with them, it was perhaps simply putting more work into them than someone else would have; to [quote Teller](https://www.smithsonianmag.com/arts-culture/teller-reveals-his-secrets-100744801/ "Teller Reveals His Secrets: The smaller, quieter half of the magician duo Penn & Teller writes about how magicians manipulate the human mind"):

> "I think you'll see what I mean if I teach you a few principles magicians employ when they want to alter your perceptions...Make the secret a lot more trouble than the trick seems worth. You will be fooled by a trick if it involves more time, money and practice than you (or any other sane onlooker) would be willing to invest."
>
> "My partner, Penn, and I once produced 500 live cockroaches from a top hat on the desk of talk-show host David Letterman. To prepare this took weeks. We hired an entomologist who provided slow-moving, camera-friendly cockroaches (the kind from under your stove don't hang around for close-ups) and taught us to pick the bugs up without screaming like preadolescent girls. Then we built a secret compartment out of foam-core (one of the few materials cockroaches can't cling to) and worked out a devious routine for sneaking the compartment into the hat. More trouble than the trick was worth? To you, probably. But not to magicians."

Besides that, I think after a while writing/research can be a virtuous circle or autocatalytic.
If one were to look at [my repo statistics](/doc/gwern.net-gitstats/index.html), you see that I haven't always been writing as much.
What seems to happen is that as I write more:

- I learn more tools

    eg. I learned basic [meta-analysis](!W) in R to answer what all the positive & negative [n-back studies](/dnb-faq "'Dual n-Back FAQ', Branwen 2009"){#dnb-faq-3} [summed to](/dnb-meta-analysis "'Dual _n_-Back Meta-Analysis', Branwen 2012"), but then I was able to use it for [iodine](/iodine#meta-analysis); I learned linear models for [analyzing _MoR_ reviews](/hpmor "‘‘HP: Methods of Rationality’ review statistics’, Branwen 2012") but now I can use them anywhere I want to, like in my [Touhou draft material](/touhou "'Touhou music by the numbers', Branwen 2013").

    The "Feynman method" has been facetiously described as "find a problem; think very hard; write down the answer", but [Gian-Carlo Rota](/doc/math/1996-04-20-rota-tenlessonsiwishihadbeentaught.html "'Ten Lessons I Wish I Had Been Taught', Rota 1996") gives the real one:

    > Richard Feynman was fond of giving the following advice on how to be a genius. You have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say: "How did he do it? He must be a genius!"
- I internalize a habit of noticing interesting questions that flit across my brain

    eg. in March 2013 while meditating: "I wonder if more doujin music gets released when unemployment goes up and people may have more spare time or fail to find jobs? Hey! That giant Touhou music torrent I downloaded, with its 45000 songs all tagged with release year, could probably answer that!" (One could argue that these questions probably *should* be ignored and not investigated in depth---Teller again---nevertheless, this is how things work for me.)
- if you aren't writing, you'll ignore useful links or quotes; but if you stick them in small asides or footnotes as you notice them, eventually you'll have something bigger.

    I grab things I see on Google Alerts & Scholar, Pubmed, Reddit, Hacker News, my RSS feeds, books I read, and note them somewhere until they amount to something. (An example would be my slowly accreting citations on [IQ and economics](/doc/iq/ses/index).)
- people leave comments, ping me on IRC, send me emails, or leave anonymous messages, all of which help

    Some examples of this come from my most popular page, on Silk Road 1:

    #. an anonymous message led me to [investigate a vendor in depth and ponder the accusation leveled against them](/silk-road#a-mole); I wrote it up and gave my opinions and thus I got another short essay to add to my SR page which I would not have had otherwise (and I think there's a [<20% chance](https://predictionbook.com/predictions/16142) that in a few years this will pay off and become a very interesting essay).
    #. CMU's Nicholas Christin, who [wrote a paper](https://www.andrew.cmu.edu/user/nicolasc/publications/Christin-WWW13.pdf "Traveling the Silk Road: A measurement analysis of a large anonymous online marketplace") by scraping SR for many months and giving all sorts of overall statistics, emailed me to point out I was citing inaccurate figures from the first version of his paper. I thanked him for the correction and while I was replying, mentioned I had a hard time believing his paper's claims about the extreme rarity of scams on SR as estimated through buyer feedback. After some back and forth and suggesting specific mechanisms how the estimates could be positively biased, he was able to check his database and confirmed that there was at least one very large omission of scams in the scraped data and there was probably a general undersampling; so now I have a more accurate feedback estimate for my SR page (important for estimating risk of ordering) and he said he'll acknowledge me in the/a paper, which is nice.

## Information organizing

Occasionally people ask how I manage information and read things.

#. For quotes or facts which are very important, I employ [spaced repetition](/spaced-repetition "'Spaced Repetition for Efficient Learning', Branwen 2009"){#srs-2} by adding them to my Mnemosyne
#. I keep web clippings in Evernotes; I also excerpt from research papers & books, and miscellaneous sources. This is useful for targeted searches when I remember a fact but not where I learned it, and for storing things which I don't want to memorize but which have no logical home in my website or LW or elsewhere. It is also helpful for writing my [book reviews](/review/book) and the [monthly newsletter](https://gwern.substack.com/ "'Gwern.net newsletter (Substack subscription page)', Branwen 2013"), as I can read through my book excerpts to remind myself of the highlights and at the end of the month review clippings from papers/webpages to find good things to reshare which I was too busy at the time to do so or was unsure of its importance. I don't make any use of more complex Evernote features.

    I periodically back up my Evernote using the [Linux client Nixnote's](https://sourceforge.net/projects/nevernote/) export feature. (I made sure there was a working export method before I began using Evernote, and use it only as long as Nixnote continues to work.)

    My workflow for dealing with PDFs, as of late 2014, is:

    #. if necessary, jailbreak the paper using Libgen or an university proxy, then upload a copy to Dropbox, named `year-author.pdf`
    #. read the paper, making excerpts as I go
    #. store the metadata & excerpts in Evernote
    #. if useful, integrate into Gwern.net with its title/year/author metadata, adding a local fulltext copy if the paper had to be jailbroken, otherwise rely on my custom archiving setup to preserve the remote URL
    #. hence, any future searches for the filename / title / key contents should result in hits either in my Evernote or Gwern.net
#. Web pages are archived & backed up by [my custom archiving setup](/archiving "'Archiving URLs', Branwen 2011"){#archiving-3}. This is intended mostly for fixing dead links (eg. to recover the fulltext of the original URL of an Evernote clipping).
#. I don't have any special book reading techniques. For really good books I excerpt from each chapter and stick the quotes into Evernote.
#. I store insights and thoughts in various pages as parenthetical comments, footnotes, and appendices. If they don't fit anywhere, I dump them in [Notes](/note/note "'Miscellaneous', Branwen 2009").
#. Larger masses of citations and quotes typically get turned into pages.
#. I make heavy use of RSS subscriptions for news. For that, I am currently using [Liferea](!W). (Not that I'm hugely thrilled about it. Google Reader was much better.)
#. For projects and followups, I use reminders in Google Calendar.
#. For recording personal data, I automate as much as possible (eg. Zeo and [arbtt](https://arbtt.nomeata.de/)) and I make a habit of the rest---getting up in the morning is a great time to build a habit of recording data because it's a time of habits like eating breakfast and getting dressed.

Hence, to refind information, I use a combination of Google, Evernote, `grep` (on the Gwern.net files), occasionally Mnemosyne, and a good visual memory.

As far as writing goes, I do not use note-taking software or things like [FreeMind](!W) or [org-mode](!W)---not that I think they are useless but I am worried about whether they would ever repay the large upfront investments of learning/tweaking or interfere with other things.
Instead, I occasionally compile outlines of articles from comments on LW/Reddit/IRC, keep editing them with stuff as I remember them, search for relevant parts, allow little thoughts to bubble up while meditating, and pay attention to when I am irritated at people being wrong or annoyed that a particular topic hasn't been written down yet.

## My Experience of Writing

What is it like to write, for me?

I would divide my writing into two types: 'incremental'/occasional, and 'big bang'.
Incremental writing is the ordinary kind of writing where I might add a quote or reference, or copyedit something, or write a small forgettable response to someone; 'big bang' writing is the more valuable sort where I sit down and bang out an entire essay like ["Why Not To Write A Book"](/book-writing "‘Why To Not Write A Book’, Gwern 2024"){.backlink-not} in a single session.

[Why don't you write?]{.marginnote} Since I find it easy to write, [I've been puzzled](https://www.lesswrong.com/posts/baTWMegR42PAsH9qJ/generalizing-from-one-example "‘Generalizing From One Example’, Alexander 2009") by the many people I know who have worthwhile things they could write, and are fully capable of 'writing' them in the sense of explaining them to me (often in text-based chat!) in sufficient detail that it could be turned into a serviceable blog post---but who **won't**.

[Typical mind.]{.marginnote} Asking them about their experience of writing, and what bars them from taking that critical step even when they agree the topic *is* worthwhile & they would like to have the writeup, I've come to realize my experience of writing is completely different from theirs.

[Blank-page tyranny.]{.marginnote} For them, the problem with longform writing is not a lack of material (my default assumption), but the writing being a school-like exercise in pain & tedium, as they struggle to fill up the blank page and assemble their atomic details into a coherent output: they struggle to take their pile of individual playing cards, and build a house of cards (which could topple at the first mistake).

[Text earworms.]{.marginnote} For me, this is almost never problem because my experience of writing is **radically different**.
I rarely struggle with assembling my fragments into a whole, because the whole instead inflicts itself on me.
Much of my writing is like a [musical earworm](!W) or [intrusive thought](!W): I experience the rumination as a mental voice reciting a paragraph, looping indefinitely, until I suppress it or get distracted (but then it may return, of its own volition).
The paragraph might be a dialogue^[I avoid writing these down. Dialogue is a deceptively difficult genre outside of pedagogy like [inquiry-based learning](!W)/["discovery fiction"](https://michaelnotebook.com/df/index.html), and most dialogues would be better off as ["classic style"](/review/book#clear-and-simple-as-the-truth-thomas-1996) essays.], a comment in reply to someone specific, or on a general topic, a tweet, an email, or it might be the key paragraph for an essay I've been musing for a while---anything, really.
The paragraph usually starts as a tangled rat's-nest of fragments, allusions, citations, and parenthetical digressions, and gradually cleans itself up into something more readable.
(One can always tell when I wrote something in a rush, without the benefit of revision to flatten it out, because of the nested parentheticals and tangents.)

[^dreaming]: Sometimes, when quasi-lucid-dreaming, I can 'read' a website, especially Twitter, and the text is genuinely there (because I can transcribe some of them upon waking) and written in all variety of styles just like the real thing. An example:

    > Still the best poem not about God 🦋🥅
    >
    >> Fire is the only path between ice.

    This is original, but I didn't write it, so who did? Eerily, the dream *feels* completely effortless---the rest of my brain must be busy babbling away predicting arbitrary Internet text as if it were GPT-3, yet like a human [confabulating](!W "Confabulation"), there is no conscious awareness of that effort.

[Transcription.]{.marginnote} The voice is clearly myself, and does not feel like any kind of muse or external force, any more than a musical earworm or phrase feels "alien" to you; but it is effortless and involuntary[^dreaming], and hard to make it go away, which can be annoying.
So I put down my writings into my website in order to forget the writings in my head.
Thus, 'big bang' writing is easy---I am simply an amanuensis for the voice in my head.
The key text has repeated itself so often that I can write it in a sitting.
Indeed, these paragraphs have repeated themselves so many times that I am barely even thinking about this as I write it.
(Instead I am thinking about a different topic: the value of writing a book vs blog posts.)
I don't experience the 'tyranny of the blank page', so much as the 'tyranny of transcription'.

[90% done.]{.marginnote} The real pain comes in the editing process afterwards, where I must laboriously stitch together the fragments and copyedit and add references and markup.
(The voice is no help there, having gone silent once the loop has been written down.)
The 'incremental' phase of writing is frustrating enough that I generally avoid writing as long as I can, in the hopes that the voice will give up and go away.[^graphomania]
If I cannot outwait the recitation, if it keeps returning over enough periods, or some specific reason comes up (like an interested reader), then I may bother to write it down (rather than do something more fun, like read new research papers).

[^graphomania]: Critics sometimes mock me & [Scott Alexander](https://www.reddit.com/r/slatestarcodex/comments/8e2838/ama_request_with_scott/dxv9let/ "‘Q: How do you write so quickly?’, Alexander 24 A") & [Eliezer Yudkowsky](!W) for verbosity unto [graphomania](!W)/[hypergraphia](!W)/[logorrhea](https://en.wikipedia.org/wiki/Logorrhea_(psychology)).

    While this is wrong as a psychiatric diagnosis---we can both easily just not write, experience no difficulties in ordinary life due to the desire to write, and are not *compelled* to do so, much less to the extreme of scribbling nonsense on paper (eg. [Charles Crumb](https://www.lambiek.net/artists/c/crumb_charles.htm))---there is probably something to the weaker claim that there is a *spectrum* of writing-motivation (of which hypergraphia is the pathological extreme) and we are far above average on it, and this is the [ur-fascination](https://slatestarcodex.com/2013/06/30/the-lottery-of-fascinations/) which critically contributes to our ["writing pipeline"](/note/pipeline "‘Leaky Pipelines’, Gwern 2014") (but where other people leak out).

    Since we don't know what it's like to be other people, it is easy to misunderstand how writing feels to other people---I am reminded of [Donald Knuth & Chuck Moore](/backstop#knuth)'s difficulty understanding how the rest of us struggle to read or write computer programs.

[No free lunch.]{.marginnote} But that is only my *experience* of writing.
Even if it does not feel like effortful thinking, and often like simply writing down something 'obvious', the voice comes from somewhere, and is not divine inspiration.
The underlying reality must be the usual one: writing is like gardening.
One patiently tends one's garden, seeding and watering and pruning, and green shoots come up, and one day, one may behold a sudden blossoming, which one may cut and put in a vase to be seen by all.
Or not, and let it wither and fall.

## Confidence tags

<span id="belief-tags"></span>

Most of the metadata in each page is self-explanatory: the date is the last time the page was meaningfully modified^[I originally used last file modification time but this turned out to be confusing to readers, because I so regularly add or update links or add new formatting features that the file modification time was usually quite recent, and so it was meaningless.], the tags are categorization, etc.
The "status" tag describes the state of completion: whether it's a pile of links & snippets & "notes", or whether it is a "draft" which at least has some structure and conveys a coherent thesis, or it's a well-developed draft which could be described as "in progress", and finally when a page is done---in lieu of additional material turning up---it is simply "finished".

The "confidence" tag is a little more unusual.
I stole the idea from [Muflax's "epistemic state"](https://web.archive.org/web/20110927151625/http://muflax.com/episteme/ "'I wanted a way to show whether I still believe something I have written or not, and if so, how strongly.' (original: http://muflax.com/episteme/)") tags; I use the same meaning for "log" for collections of data or links ("log entries that simply describe what happened without any judgment or reflection") personal or reflective writing can be tagged "emotional" ("some cluster of ideas that got itself entangled with a complex emotional state, and I needed to externalize it to even look at it; in no way endorsed, but occasionally necessary (similar to fiction)"), and "fiction" needs no explanation (every author has *some* reason for writing the story or poem they do, but not even they always know whether it is an expression of their deepest fears, desires, history, or simply random thoughts).
I drop his other tags in favor of giving my subjective probability using the ["Kesselman List of Estimative Words"](/doc/statistics/bayes/2008-kesselman.pdf "'Verbal probability expressions in National Intelligence Estimates: a comprehensive analysis of trends from the fifties through post 9/11', Kesselman 2008"):

#. "certain"
#. "highly likely"
#. "likely"
#. "possible" (my preference over Kesselman's "Chances a Little Better [or Less]")
#. "unlikely"
#. "highly unlikely"
#. "remote"
#. "impossible"

These are used to express my feeling about how well-supported the essay is, or how likely it is the overall ideas are right.
(Of course, an interesting idea may be worth writing about even if very wrong, and even a long shot may be profitable to examine if the potential payoff is large enough.)

## Importance tags

An additional useful bit of metadata would be distinction between things which are trivial and those which are about more important topics which might change your life.
Using [my interactive sorting tool Resorter](/resorter "'Resorting Media Ratings', Branwen 2015"), I've ranked pages in deciles from 0--10 on how important the topic is to myself, the intended reader, or the world.
For example, topics like [embryo selection for traits such as intelligence](/embryo-selection "'Embryo Selection For Intelligence', Branwen 2016") or [evolutionary pressures towards autonomous AI](/tool-ai "'Why Tool AIs Want to Be Agent AIs', Branwen 2016") are vastly more important, and be ranked 10, than some poems or a dream or someone's small nootropics self-experiment, which would be ranked 0--1.

## Writing checklist

It turns out that writing essays (technical or philosophical) is a lot like writing code---there are so many ways to err that you need a process with as much automation as possible. My current checklist for finishing an essay:

- syntax:

    - [balanced brackets & quotes check](https://www.emacswiki.org/emacs/MarkdownMode)
    - do a Pandoc/Firefox preview for visible major formatting problems
    - [Markdown lint-checker](#markdown-checker)
    - [`linkchecker`](https://github.com/linkchecker/linkchecker) for

        #. dead links
        #. inserting into [archive queue](/archiving "'Archiving URLs', Branwen 2011"){#archiving-4}
- references:

    - for academic hyperlinks, include a [tooltip](!W) with the title & author metadata
    - for any papers cited: either link full text, provide a local full text, or submit a request on [/r/Scholar](https://www.reddit.com/r/Scholar/) or [LessWrong](https://www.lesswrong.com/posts/4sAsygakd4oCpbEKs/lesswrong-help-desk-free-paper-downloads-and-more-2014 "Free research help, editing and article downloads for LessWrong"); for books, insert an Amazon link if a copy can't be hosted
- language:

    - [spellcheck](!W "Ispell")
    - check readability level (eg. [Flesch-Kincaid](!W))
    - [probability word checklist](#confidence-tags)
    - check for use of the word "significant"/"significance" and insert "[statistically]" as appropriate (to disambiguate between [effect sizes](!W) and [statistical-significance](!W); this common confusion is one reason for ["statistical-significance considered harmful"](https://www.lesswrong.com/posts/ttvnPRTxFyru9Hh2H/against-nhst "Against NHST"))
    - convert English units to metric
    - [proselint](https://github.com/amperser/proselint/) checks
- content:

    - mention any use of PredictionBook in [my essay on forecasting & prediction markets](/prediction-market "'Prediction Markets', Branwen 2009")
    - mention any use of Fermi estimates in [Fermi calculations](/note/fermi "'Fermi Calculation Examples', Branwen 2019")
    - arrange for notifications of future results (when deciding to do long-term followups, eg. dual _n_-back research):

        #. [Google Alerts](https://www.google.com/alerts)
        #. [Google Scholar Alerts](https://scholar.googleblog.com/2010/06/google-scholar-alerts.html)
        #. [PubMed](!W) alerts
    - if using statistics:

        - rerun all code to verify reproducibility
        - use reporting/quality checklists:

             - cross-sectional & other non-randomized analyses: [STROBE](https://journals.plos.org/plosmedicine/article/info%3Adoi%2F10.1371%2Fjournal.pmed.0040297 "'Strengthening the Reporting of Observational Studies in Epidemiology (STROBE): Explanation and Elaboration', Vandenbroucke et al 2007")
             - randomized experiments: [CONSORT](/doc/statistics/2010-consort-checklist.jpg) ([statement](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2860339/ "'CONSORT 2010 Statement: Updated Guidelines for Reporting Parallel Group Randomized Trials', Schulz et al 2010"))
             - meta-analyses: [PRISMA](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1000097 "'Preferred Reporting Items for Systematic Reviews and Meta-Analyses: The PRISMA Statement', Moher et al 2009")
- after publication, publicize; currently:

    #. Hacker News
    #. Reddit
    #. LessWrong (and further sites as appropriate)
    #. Twitter

### Markdown checker

I've found that many errors in my writing can be caught by some simple scripts, which I've compiled into a shell script, [`markdown-lint.sh`](/static/build/markdown-lint.sh).

My linter does:

#. checks for corrupted non-text binary files
#. checks a blacklist of domains which are either dead (eg. Google+) or have a history of being unreliable (eg. ResearchGate, NBER, PNAS); such links need^[Reactive archiving is inadequate because such links may die before my crawler gets to them, may not be archivable, or will just expose readers to dead links for an unacceptably long time before I'd normally get around to them.] to either be fixed, pre-emptively mirrored, or removed entirely.

    - a special case is PDFs hosted on IA; the IA is reliable, but I try to rehost such PDFs so they'll show up in Google/Google Scholar for everyone else.
#. Broken syntax: I've noticed that when I make Markdown syntax errors, they tend to be predictable and show up either in the original Markdown source, or in the rendered HTML. Two common source errors:

        "(www"
        ")www"

    And the following should *rarely* show up in the final rendered HTML:

        "\frac"
        "\times"
        "(http"
        ")http"
        "[http"
        "]http"
        " _ "
        "[^"
        "^]"
        "<!--"
        "-->"
        "<-- "
        "<-"
        "->"
        "$title$"
        "$description$"
        "$author$"
        "$tags$"
        "$category$"

    Similarly, I sometimes slip up in writing image/document links so any link starting `https://gwern.net` or `~/wiki/` or `/home/gwern/` is probably wrong. There are a few Pandoc-specific issues that should be checked for too, like duplicate footnote names and images without separating newlines or unescaped dollar signs (which can accidentally lead to sentences being rendered as <span class="logotype-tex">T<sub>e</sub>X</span>).

    A final pass with [`htmltidy`](https://www.html-tidy.org/) finds many errors which slip through, like incorrectly-escaped URLs.
#. Flag dangerous language: Imperial units are deprecated, but so too is the misleading language of NHST statistics (if one must talk of "significance" I try to flag it as "statistically-significant" to warn the reader). I also avoid some other dangerous words like "obvious" (if it is really is, why do I need to say it?).
#. Bad habits:

    - [`proselint`](http://proselint.com/) (with some checks disabled because they play badly with Markdown documents)
    - Another static warning is checking for too-long lines (most common in code blocks, although sometimes broken indentation will cause this) which will cause browsers to use scrollbars, for which I've written a [Pandoc script](/static/build/markdown-length-checker.hs),
    - one for a bad habit of mine---[too-long footnotes](/static/build/markdown-footnote-length.hs)
#. duplicate and hidden-PDF URLs: a URL being linked multiple times is sometimes an error (too much copy-paste or insufficiently edited sections); PDF URLs should receive a visual annotation warning the reader it's a PDF, but the CSS rules, which catch cases like `.pdf$`, don't cover cases where the host quietly serves a PDF anyway, so all URLs are checked. (A URL which is a PDF can be made to trigger the PDF rule by appending `#pdf`.)
#. broken links are detected with [`linkchecker`](https://github.com/linkchecker/linkchecker). The best time to fix broken links is when you're already editing a page.

While this throws many false positives, those are easy to ignore, and the script fights bad habits of mine while giving me much greater confidence that a page doesn't have any merely technical issues that screw it up (without requiring me to constantly reread pages every time I modify them, lest an accidental typo while making an edit breaks everything).

### Anonymous feedback

Back in November 2011, lukeprog posted ["Tell me what you think of me"](https://www.lesswrong.com/posts/zFj67rtrQ7HEaZ45F/tell-me-what-you-think-of-me) where he described his use of a Google Docs form for anonymous receipt of textual feedback or comments. Typically, most forms of communication are non-anonymous, or if they are anonymous, they're public. One can set up pseudonyms and use those for private contact, but it's not always that easy, and is definitely a series of [trivial inconveniences](https://www.lesswrong.com/posts/reitXJgJXFzKpdKyd/beware-trivial-inconveniences "'Beware Trivial Inconveniences', Alexander 2009") (if anonymous feedback is not solicited, one has to feel it's important enough to do and violate implicit norms against anonymous messages; one has to set up an identity; one has to compose and send off the message, etc).

I thought it was a good idea to try out, and on 2011-11-08, I set up my own anonymous feedback form and stuck it in the footer of all pages on Gwern.net where it remains to this day. I did wonder if anyone would use the form, especially since I am easy to contact via email, use multiple sites like Reddit or Lesswrong, and even my Disqus comments allowed anonymous comments---so who, if anyone, would be using this form? I scheduled a followup in 2 years on 2013-11-30 to review how the form fared.

754 days, 2.884m page views, and 1.350m unique visitors later, I have received 116 pieces of feedback (mean of 24.8k visits per feedback). I categorize them as follows in descending order of frequency:

- Corrections, problems (technical or otherwise), suggested edits: 34
- Praise: 31
- Question/request (personal, tech support, etc): 22
- Misc (eg. gibberish, socializing, Japanese): 13
- Criticism: 9
- News/suggestions: 5
- Feature request: 4
- Request for cybering: 1
- Extortion: 1 (see my [blackmail page](/blackmail#september) dealing with the September 2013 incident)

Some submissions cover multiple angles (they can be quite long), sometimes people double-submitted or left it blank, etc, so the numbers won't sum to 116.

In general, a lot of the corrections were usable and fixed issues of varying importance, from typos to the entire site's CSS being broken due to being uploaded with the wrong MIME type. One of the news/suggestion feedbacks was very valuable, as it lead to writing the Silk Road mini-essay ["A Mole?"](/silk-road#a-mole){#mole-2} A lot of the questions were a waste of my time; I'd say half related to Tor/Bitcoin/Silk-Road. (I also got an irritating number of emails from people asking me to, say, buy LSD or heroin off SR for them.) The feature requests were usually for a better RSS feed, which I tried to oblige by starting the [Changelog](/changelog){#gwern-changelog} page. The cybering and extortion were amusing, if nothing else. The praise was good for me mentally, as I don't interact much with people.

I consider the anonymous feedback form to have been a success, I'm glad lukeprog brought it up on LW, and I plan to keep the feedback form indefinitely.

#### Feedback causes

One thing I wondered is whether feedback was purely a function of traffic (the more visits, the more people who could see the link in the footer and decide to leave a comment), or more related to time (perhaps people returning regularly and eventually being emboldened or noticing something to comment on). So I compiled daily hits, combined with the feedback dates, and looked at a graph of hits:

![Hits over time for Gwern.net](/doc/traffic/2013-11-30-gwern-gwernnet-hitsovertime.jpg)

The hits are heavily skewed by Hacker News & Reddit traffic spikes, and probably should be log transformed. Then I did a logistic regression on hits, log hits, and a simple time index:

~~~{.R}
feedback <- read.csv("https://gwern.net/doc/traffic/2013-gwern-gwernnet-anonymousfeedback.csv",
                     colClasses=c("Date","logical","integer"))
plot(Visits ~ Day, data=feedback)
feedback$Time <- 1:nrow(feedback)
summary(step(glm(Feedback ~ log(Visits) + Visits + Time, family=binomial, data=feedback)))
# ...
# Coefficients:
#              Estimate Std. Error z value Pr(>|z|)
# (Intercept) -7.363507   1.311703   -5.61  2.0e-08
# log(Visits)  0.749730   0.173846    4.31  1.6e-05
# Time        -0.000881   0.000569   -1.55     0.12
#
# (Dispersion parameter for binomial family taken to be 1)
#
#     Null deviance: 578.78  on 753  degrees of freedom
# Residual deviance: 559.94  on 751  degrees of freedom
# AIC: 565.9
~~~

The logged hits works out better than regular hits, and survives to the simplified model. And the traffic influence seems much larger than the time variable (which is, curiously, negative).

# Technical aspects

## Popularity

> On a semi-annual basis, since 2011, I review Gwern.net website traffic using Google Analytics; although what most readers value is not what I value, I find it motivating to see total traffic statistics reminding me of readers (writing can be a lonely and abstract endeavour), and useful to see what are major referrers.
>
> Gwern.net typically enjoys steady traffic in the 50--100k range per month, with occasional spikes from social media, particularly Hacker News; over the first decade (2010--2020), there were 7.98m pageviews by 3.8m unique users.

<span id="july-2016---january-2017">**See [Gwern.net Website Traffic](/traffic "Meta page describing Gwern.net editing activity, traffic statistics, and referrer details, primarily sourced from Google Analytics (2011-present).")**</span>

## Colophon

### Hosting

Gwern.net is served by [Amazon S3](!W) through the [CloudFlare](!W) [CDN](!W "Content delivery network"). (Amazon charges less for bandwidth and disk space than [NearlyFreeSpeech.net](https://www.nearlyfreespeech.net/), an old hosting company I originally used, although one loses all the capabilities offered by Apache's [.htaccess](!W), and [Brotli](!W) compression is difficult so must be handled by CloudFlare; total costs may turn out to be a wash and I will consider the switch to Amazon S3 a success if it can bring my monthly bill to <\$10 or <\$120 a year.)

From October 2010 to June 2012, the site was hosted on NFSN; its specific niche is controversial material and activist-friendly pricing.
Its libertarian owners cast a jaundiced eye on [takedown requests](!W), and pricing is pay-as-you-go. I like the former aspect, but the latter sold me on NFSN. Before I stumbled on NFSN (someone mentioned it offhandedly while chatting), I was getting ready to pay \$10--15 a month (\$120 yearly) to [Linode](!W). Linode's offerings are overkill since I do not run dynamic websites or something like [Haskell.org](https://www.haskell.org/) (with wikis and mailing lists and [darcs](!W) repositories), but I didn't know a good alternative. NFSN's pricing meant that I paid for usage rather than large flat fees. I put in \$32 to cover registering Gwern.net until 2014, and then another \$10 to cover bandwidth & storage price. DNS aside, I was billed \$8.27 for October-December 2010; DNS included, January-April 2011 cost \$10.09. \$10 covered months of Gwern.net for what I would have paid Linode in 1 month! In total, my 2010 costs were \$39.44 ([bill archive](/doc/traffic/2010-gwern-gwernnet-nfsncosts.maff)); my 2011 costs were \$118.32 (\$9.86 a month; [archive](/doc/traffic/2011-gwern-gwernnet-nfsncosts.maff)); and my 2012 costs through June were \$112.54 (\$21 a month; [archive](/doc/traffic/2012-gwern-gwernnet-nfsncosts.maff)); sum total: \$270.3.

The switch to Amazon S3 hosting is complicated by my simultaneous addition of CloudFlare as a CDN; my total June 2012 Amazon bill is \$1.62, with \$0.19 for storage. CloudFlare claims it covered 17.5GB of 24.9GB total bandwidth, so the \$1.41 represents 30% of my total bandwidth; multiply 1.41 by 3 is 4.30, and my hypothetical non-CloudFlare S3 bill is ~\$4.5. Even at \$10, this was well below the \$21 monthly cost at NFSN. (The traffic graph indicates that June 2012 was a relatively quiet period, but I don't think this eliminates the factor of 5.) From July 2012 to June 2013, my Amazon bills totaled \$60, which is reasonable except for the steady increase (\$1.62/\$3.27/\$2.43/\$2.45/\$2.88/\$3.43/\$4.12/\$5.36/\$5.65/\$5.49/\$4.88/\$8.48/\$9.26), being primarily driven by out-bound bandwidth (in June 2013, the \$9.26 was largely due to the 75GB transferred---and that was *after* CloudFlare dealt with 82GB); \$9.26 is much higher than I would prefer since that would be >\$110 annually. This was probably due to all the graphics I included in the "Google shutdowns" analysis, since it returned to a more reasonable \$5.14 on 42GB of traffic in August. September, October, November and December 2013 saw high levels maintained at \$7.63/\$12.11/\$5.49/\$8.75, so it's probably a new normal.
2014 entailed new costs related to EC2 instances & S3 bandwidth spikes due to hosting a multi-gigabyte scientific dataset, so bills ran \$8.51/\$7.40/\$7.32/\$9.15/\$26.63/\$14.75/\$7.79/\$7.98/\$8.98/\$7.71/\$7/\$5.94.
2015 & 2016 were similar: \$5.94/\$7.30/\$8.21/\$9.00/\$8.00/\$8.30/\$10.00/\$9.68/\$14.74/\$7.10/\$7.39/\$8.03/\$8.20/\$8.31/\$8.25/\$9.04/\$7.60/\$7.93/\$7.96/\$9.98/\$9.22/\$11.80/\$9.01/\$8.87.
2017 saw costs increase due to one of my side-projects, aggressively increasing fulltexting of Gwern.net by providing more papers & scanning cited books, only partially offset by changes like lossy optimization of images & converting GIFs to WebMs: \$12.49/\$10.68/\$11.02/\$12.53/\$11.05/\$10.63/\$9.04/\$11.03/\$14.67/\$15.52/\$13.12/\$12.23 (total: \$144.01).
In 2018, I continued fulltexting: \$13.08/\$14.85/\$14.14/\$18.73/\$18.88/\$15.92/\$15.64/\$15.27/\$16.66/\$22.56/\$23.59/\$25.91/(total: \$213).

For 2019, I made a determined effort to host more things, including whole websites like the OKCupid archives or `rotten.com`, and to include more images/videos (the StyleGAN anime faces tutorial alone must be easily 20MB+ just for images) and it shows in how my bandwidth costs exploded: [$26.49]($2019)/[$37.56]($2019)/[$37.56]($2019)/[$37.56]($2019)/[$25.00]($2019)/[$25.00]($2019)/[$25.00]($2019)/[$25.00]($2019)/[$77.91]($2019)/[$124.45]($2019)/[$74.32]($2019)/[$79.19]($2019).
I began considering a move of Gwern.net to my Hetzner dedicated server which has cheap bandwidth + ~6tb space, combined with upgrading my Cloudflare CDN to keep site latency in check (even at [$20]($2020)/month, it's still far cheaper than AWS S3 bandwidth).

In 2020, I did so, merging the hosting of Gwern.net, ThisWaifuDoesNotExist, Danbooru20xx, miscellaneous ML datasets & models, all onto a single Hetzner dedicated server, for ~[$50]($2020)/month.
With uncapped bandwidth, I could be much more aggressive about hosting files and automatically archiving webpage snapshots.
This was highly satisfactory for the next 2 years, but the growth of Danbooru20xx eventually exceded the drive space and I relocated to another server with >20tb space, costing ~[$60]($2022).
(I didn't need the full 20tb immediately but that left a large safety margin and I was thinking of creating some additional datasets like Danbooru20xx, using Derpibooru & e621---the goal being to eventually create a single model handling all kinds of illustration-based fandoms with much higher quality than the default of everyone creating their own small underpowered model on just their personal interest.)

<!-- ledger reg 'hosting:S3' -p 'monthly' -p 'last year' -->

### Source

The revision history is kept in git; individual Markdown page sources can be read by appending `.md` to their URL (eg. [for this page](/about.md)).
The site infrastructure is available [on Github](https://github.com/gwern/gwern.net/){#site-infrastructure-repo}.

#### Size

As of 2022-11-08, the source of Gwern.net is composed of >443 text files with >4.38m words or >31MB<!-- du -ch `find . -type f -name "*.md" | fgrep -v -e 'index.md'` -->; this includes my writings & documents I have transcribed into Markdown, but excludes images, PDFs, HTML mirrors, source code, archives, infrastructure (such as tag-directories), popup and the revision history. <!-- cat `find . -type f -name "*.md" | fgrep -v -e 'index.md'` | wc --words -->
With those included and everything compiled to the static^[I like the static site approach to things; it tends to be harder to use and more restrictive, but in exchange it yields [better performance](https://inessential.com/2011/03/16/a_plea_for_baked_weblogs) & leads to fewer [hassles or runtime issues](http://www.aaronsw.com/weblog/000404). The static model of compiling a single monolithic site directory also lends itself to testing: any shell script or CLI tool can be easily run over the compiled site to find potential bugs (which has become increasingly important as site complexity & size increases so much that eyeballing the occasional page is inadequate).] HTML, the site is >72GB.
The source repository contains >16,629 patches<!-- git rev-list HEAD - - count --> (this is an under-count as the creation of the repository in 2008-09-26 included already-written material); the [infrastructure repository](#site-infrastructure-repo), >5,807.

### Design

<span id="tools">[**Moved to "Design Of This Website".**](/design "'Design Of This Website', Branwen 2010"){#design-2 .include-annotation .backlink-not}</span>

### License

This site is licensed under the [Creative Commons](!W) [public domain (CC-0)](https://creativecommons.org/public-domain/cc0/) license.

I believe the public domain license reduces [FUD](!W "Fear, uncertainty and doubt") and [dead-weight loss](!W)[^access], encourages copying ([LOCKSS](!W)), gives back (however little) to [Free Software](!W)/[Free Content](!W), and costs me nothing^[Not that I *could* sell anything on this wiki; and if I could, I would polish it as much as possible, giving me fresh copyright.].

[^access]: PD increases economic efficiency through---if nothing else---making works easier to find. [Tim O’Reilly](!W) says that ["Obscurity is a far greater threat to authors and creative artists than piracy."](http://www.openp2p.com/pub/a/p2p/2002/12/11/piracy.html "'Piracy is Progressive Taxation, and Other Thoughts on the Evolution of Online Distribution', O`Reilly 2002") If that is so, then that means that difficulty of finding works reduces the welfare of artists *and* consumers, because both forgo a beneficial trade (the artist loses any revenue and the consumer loses any enjoyment). Even small increases in inconvenience make [big differences](/inclusionism#new-regimes).

# Appendix
## Benford’s law {.collapse}

<div class="abstract">
> Does Gwern.net follow the famous Benford’s law?
>
> A quick analysis suggests that it sort of does, except for the digit 2, probably due to the many citations to research from the past 2 decades (>2000 AD).
</div>

In March 2013 I wondered, upon seeing a mention of [Benford’s law](!W): "if I extracted all the numbers from everything I've written on Gwern.net, would it satisfy Benford’s law?" It seems the answer is... *almost*. I generate the list of numbers by running a Haskell program to parse digits, commas, and periods; and then I process it with shell utilities.[^Benford-Haskell] This can then be read in R to run a [chi-squared test](!W) confirming lack of fit (_p_ ≈ 0) and generate this comparison of the data & Benford’s law[^Benford-R]:

![Histogram/barplot of parsed numbers vs predicted](/doc/traffic/2013-gwern-benfords-law.png){.invert}

There's a clear resemblance for everything but the digit '2', which then blows the fit to heck. I have no idea why 2 is overrepresented---it may be due to all the citations to recent academic papers which would involve numbers starting with '2' (2002, 2010, 2013...) and cause a double-count in both the citation and filename, since if I look in the `docs/` fulltext folder, I see 160 files starting with '1' but 326 starting with '2'. But this can't be the entire explanation since '2' has 20.3k entries while to fit Benford, it needs to be just 11.5k---leaving a gap of ~10k numbers unexplained. A mystery.

[^Benford-Haskell]: We write a short Haskell program as part of a pipeline:

    ~~~{.Bash}
    echo '{-# LANGUAGE OverloadedStrings #-};
          import qualified Data.Text as T;
          main = interact (T.unpack . T.unlines . Prelude.filter (/="") .
                           T.split (not . (`elem` "0123456789,.")) . T.pack)' > ~/number.hs &&
    find ~/wiki/ -type f -name "*.md" -exec cat "{}" \; | runghc ~/number.hs |
     sort | tr -d ',' | tr -d '.' | cut -c 1 | sed -e 's/0$//' -e '/^$/d' > ~/number.txt
    ~~~

    <!-- " -->
[^Benford-R]: Graph then test:

    ~~~{.R}
    numbers <- read.table("number.txt")
    ta <- table(numbers$V1); ta

    #     1     2     3     4     5     6     7     8     9
    # 20550 20356  7087  5655  3900  2508  2075  2349  2068
    ## cribbing exact R code from http://www.math.utah.edu/~treiberg/M3074BenfordEg.pdf
    sta <- sum(ta)
    pb <- sapply(1:9, function(x) log10(1+1/x)); pb
    m <- cbind(ta/sta,pb)
    colnames(m)<- c("Observed Prop.", "Theoretical Prop.")
    barplot( rbind(ta/sta,pb/sum(pb)), beside = T, col = rainbow(7)[c(2,5)],
                  xlab = "First Digit")
    title("Benford's Law Compared to Writing Data")
    legend(16,.28, legend = c("From Page Data", "Theoretical"),
           fill = rainbow(7)[c(2,5)],bg="white")
    chisq.test(ta,p=pb)
    #
    #     Chi-squared test for given probabilities
    #
    # data:  ta
    # X-squared = 9331, df = 8, p-value < 2.2e-16
    ~~~